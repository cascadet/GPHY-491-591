{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPHY 491-591: Lab 3\n",
    "\n",
    "Written by Cascade Tuholske, Jan. 2024\n",
    "\n",
    "![Richmond](./assets/richmond.png)\n",
    "\n",
    "## Goals\n",
    "The goal of Lab 3 is to use our new knowledge of `Pandas`, `GeoPandas` and `Rasterio` to create a human-environment geospatial data to investigate the relationship between socioeconomic status, green space, and temperature in Los Angeles, California. In urban areas, the distribution of materials such as asphalt and concrete has been shown to lead to higher surface and air temperatures compared to rural counterparts. This is known as the urban heat island (UHI) effect. High temperatures can be harmful to the health of residents, and in order to mitigate the UHI cities adopt strategies like increasing tree cover to increase shade and cooling, or increasing the reflectivity, also called albedo, with white paint. \n",
    "\n",
    "It has been shown that within most cities, the UHI and exposure to extreme heat is most pronounced in neighbhorhoods who house the most structuralized margalized. The image above is from a wonderful [article](https://www.nytimes.com/interactive/2020/08/24/climate/racism-redlining-cities-global-warming.html) in the New York Times about racist redlining policies, green space, and heat exposure in Richmond, VA. **The question is: how are datasets like the one used in this article created?**\n",
    "\n",
    "To answer this question, you will combine demographic and socioeconomic data from the LA Times ([read about it here](http://maps.latimes.com/neighborhoods)) and remote sensed data from [Landsat satellites](https://landsat.gsfc.nasa.gov). Not only will you become familiar with a suite of Python tools, you will learn about a bit about physics, spatial uncertainty, demography, and environmental justice. In  short, you will assemble and analyze a dataset that captures a snapshot of approximate average midday temperatures in May and August, the amount of vegetation, and a host of social/economic data across each neighborhood in the county of Los Angeles. \n",
    "\n",
    "In terms of new Python tools, you will be given a series of custom [functions](https://www.codecademy.com/learn/cspath-cs-101/modules/cspath-python-functions/cheatsheet). We will cover functions in detail in lecture, but I want to give you a chance to see what they are and how they will speed up your code. Don't worry if they don't fully make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "Here you will cover the basics of functions. You define functions using the `def` key word and you use `()` to state the parameters (or arguments) that the function needs to be passed to be implemented. Not all functions require parameters. A few things to note: \n",
    "1. Variables assigned within a function are local (e.g. exist within the function) and those outside functions are global (e.g. accessable by all parts of your code). \n",
    "2. To get the output of a function, you must use the key word `return`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function\n",
    "def my_func(x, y):\n",
    "    ans = x * y\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code\n",
    "x = 1\n",
    "y = 2\n",
    "ans = my_func(x, y)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code\n",
    "z = 7\n",
    "c = 12\n",
    "ans = my_func(z, c)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code\n",
    "z = 7\n",
    "c = 12\n",
    "ans = my_func(x = z, y = c)\n",
    "print(ans)\n",
    "print('x', x)\n",
    "print('y', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `x` and `y` are not reassigned the values inside `my_fun(x = z, y = c)` but are called locally by `my_func`. <br>\n",
    "\n",
    "You can also call functions within functions. Or, even create functions inside functions. Don't worry about this for now, but I do want you to play with the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code\n",
    "def my_helper(x):\n",
    "    ans = x**2\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this code\n",
    "ans = my_func(x = z, y = c)\n",
    "print(ans)\n",
    "ans = my_func(x = my_helper(z), y = c)\n",
    "print(ans)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code\n",
    "def my_new_func(x, y):\n",
    "    \n",
    "    x2 = my_helper(x)\n",
    "    \n",
    "    ans = x2 * y\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 7\n",
    "c = 12\n",
    "ans = my_new_func(x = z, y = c)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: \n",
    "Explain what four code cells above above did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding comments tripple quote docstring is very important to documenting functions. Admittedly, the functions I provide later in this lab are poorly documented. Don't me like me - be good at documenting your code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code\n",
    "def my_new_func(x, y):\n",
    "    \n",
    "    \"\"\" Function that squares the first value and then multiplies it by the second value. Returns an answer:\n",
    "    \n",
    "    ans = x**2 * y\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x = number to be squared\n",
    "    y = number to be multiplied. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    x2 = my_helper(x) # See my_helper for details\n",
    "    \n",
    "    ans = x2 * y\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this code\n",
    "help(my_new_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "We are now going to dive into the the neighbhorhood-level socioeconomic and demographic data provide by the LA Times. You are lucky - I downloaded this data for you to use. But you will have to merge the files I downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Depedencies\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio \n",
    "from rasterstats import zonal_stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up your file path\n",
    "file_path = os.path.join('/home/group/earthsciences/gphy591/github/GPHY-491-591/materials/Day5/data/Lab3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open shape files with neigbhorhood boundaries\n",
    "neighborhoods_fn = os.path.join(file_path, 'la_county/la_county.shp')\n",
    "neighborhoods = gpd.read_file(neighborhoods_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On your own ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the columns of neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the shape of neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a quick plot of neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: \n",
    "What data does neighborhoods provide, if any at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the socioeconomic files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new file path\n",
    "se_dir = os.path.join(file_path, 'socioeconomic/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use glob and the wildcard * to look at the files in se_dir\n",
    "glob(se_dir+'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: \n",
    "What type of object does `glob` produce?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a DataFrame to Merge the Files \n",
    "df_out = neighborhoods[['Name']]\n",
    "df_out.rename(columns={'Name':'NEIGHBORHOOD'}, inplace=True) # rename col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through files and write out csv\n",
    "for fn in os.listdir(se_dir):\n",
    "    \n",
    "    col = fn.split('LA-')[1].split('.csv')[0] # Get col name\n",
    "    df = pd.read_csv(se_dir+fn) # open the fn\n",
    "\n",
    "    if df.shape[1] == 3:\n",
    "        df_out = df_out.merge(df.iloc[:,1:3], on = 'NEIGHBORHOOD', how = 'left') # merge \n",
    "    \n",
    "    elif df.shape[1] == 4: # crime\n",
    "        df_out = df_out.merge(df.iloc[:,1:4], on = 'NEIGHBORHOOD', how = 'left') # merge\n",
    "        df_out.rename(columns = {'PER CAPITA' : \"CRIME PER CAPITA\"}, inplace = True)\n",
    "        df_out.rename(columns = {'TOTAL' : \"CRIME TOTAL\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check out df_out\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write csv\n",
    "fn_out = os.path.join('./data/', 'LA-all-SE-data') # SE = socioeconomic\n",
    "df_out.to_csv(fn_out+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write shape file\n",
    "gdf_out = neighborhoods[['Name','geometry']] # get name and geom\n",
    "gdf_out.rename(columns={'Name':'NEIGHBORHOOD'}, inplace=True) # rename col\n",
    "gdf_out = df_out.merge(gdf_out, on = 'NEIGHBORHOOD', how = 'right') # merge the data\n",
    "gdf_out = gpd.GeoDataFrame(gdf_out) # cast to GeoPandas DF\n",
    "gdf_out.to_file(fn_out+'.shp', index = False) # save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On your own ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged SE .csv file and make sure it looks okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged SE .shp file and make sure it looks okay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "We will now dive into the Landsat data. It is important to remember that satellites collect physical data, literally photons across different bands (read up [here](https://www.usgs.gov/faqs/what-are-band-designations-landsat-satellites) and [here](https://landsat.gsfc.nasa.gov/satellites/landsat-9/landsat-9-bands/)) of the electromagnetic spectrum. The photons for each band are encoded as a digital number (DN) to keep data sizes low (see memomry matters!) for easier transmission down the earth. \n",
    "\n",
    "USGS, and others, use algorithms to translate the raw DNs to meaningful values. Each Landsat scene comes with a `.txt` file that explains how to take the [Level-1 data](https://www.usgs.gov/landsat-missions/using-usgs-landsat-level-1-data-product) and convert the various DN bands - like the thermal infrared band - to something meaningful like Top of Atmosphere Brightness Temperature (TOA BT). \n",
    "\n",
    "We will be processing two Landsat scenes: One from 2020-04-14 and one from 2020-08-20.\n",
    "\n",
    "**NOTE**: For this lab, since we are using [Level-1 data](https://www.usgs.gov/landsat-missions/using-usgs-landsat-level-1-data-product), we are literally looking at the energy being radiated from the top of the atmosphere, not what is happening on the ground. Thus, our temperature data is not land surface temperature, nor even air temperature. Furthermore, our data is not [atmospherically corrected](https://en.wikipedia.org/wiki/Atmospheric_correction). Nonetheless, the values will be illustrative. \n",
    "\n",
    "USGS provides [Level-2 data](https://www.usgs.gov/landsat-missions/landsat-collection-2-level-2-science-products), which are atmospherically corrected and provide surface reflectance and temperature values. We'll talk about this more in lecture. While my work focuses on impacts to humands on the ground, TOA data has many uses, especially for atmospheric scientists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our function to convert Landsat raw DN data to TOA BT\n",
    "\n",
    "def bright_temp(b_fn, fn_out, radiance_mult, radiance_add, k1, k2):\n",
    "    \n",
    "    \"\"\" Function writes a tif for Landsat8 brigthtness temp from DN. Note, this is not land surface tempature.\n",
    "    Args:\n",
    "        b_fn = file name for TIRS band\n",
    "        fn_out = path and file name to write .tif\n",
    "        radiance_mult, radiance_add, k1, k2 = all come from the Landsat8 Level 1 XXX_MTL.txt file\n",
    "    \"\"\"\n",
    "    # read & meta\n",
    "    meta = rasterio.open(b_fn).meta\n",
    "    meta.update({'dtype': 'float32'})\n",
    "    b = rasterio.open(b_fn).read(1)\n",
    "    \n",
    "    # Calculate TOA reflectance from DN:\n",
    "    toa  = (b * radiance_mult) + radiance_add\n",
    "    \n",
    "    # TOA to brightness temp from K to C\n",
    "    bright = (k2 / np.log(k1 / (toa +1)) - 273.15)\n",
    "    bright = np.float32(bright)\n",
    "    \n",
    "    # Drop Brightness values >50C\n",
    "    bright[bright >= 50] = np.nan\n",
    "    \n",
    "    # write our raster to disk\n",
    "    with rasterio.open(fn_out, 'w', **meta) as out:\n",
    "        out.write_band(1, bright)\n",
    "\n",
    "    print('Brightness temp done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process 2020-04-14 BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file paths\n",
    "data_in = os.path.join(file_path, 'landsat/Level1/LC08_L1TP_041036_20200414_20200423_01_T1/')\n",
    "bt_fn = os.path.join(data_in, 'LC08_L1TP_041036_20200414_20200423_01_T1_B10.TIF')\n",
    "fn_out = os.path.join('./data/', 'BT_20200414.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up constants to pass to bright_temp\n",
    "radiance_mult = 3.3420E-04\n",
    "radiance_add = 0.10000\n",
    "k1 = 774.8853\n",
    "k2 = 1321.0789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make Brightness temp -- 2020-04-14\n",
    "bright_temp(bt_fn, fn_out, radiance_mult, radiance_add, k1, k2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process 2020-08-20 BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file paths\n",
    "data_in = os.path.join(file_path, 'landsat/Level1/LC08_L1TP_041036_20200820_20200905_01_T1/')\n",
    "bt_fn = os.path.join(data_in, 'LC08_L1TP_041036_20200820_20200905_01_T1_B10.TIF')\n",
    "fn_out = os.path.join('./data/', 'BT_20200820.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up constants to pass to bright_temp\n",
    "radiance_mult = 3.3420E-04\n",
    "radiance_add = 0.10000\n",
    "k1 = 774.8853\n",
    "k2 = 1321.0789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Brightness temp -- 2020-08-20 \n",
    "bright_temp(bt_fn, fn_out, radiance_mult, radiance_add, k1, k2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On your own ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2020-04-14 BT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 2020-04-14 BT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2020-08-20 BT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 2020-08-20 BT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between 2020-08-20 and 2020-04-14 BT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the difference between 2020-08-20 and 2020-04-14 BT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "\n",
    "\n",
    "![Richmond](./assets/ndvi.png)\n",
    "\n",
    "Vegetation in LA will be characterized by the [Normalized Difference Vegetation Index (NDVI)](https://www.usgs.gov/landsat-missions/landsat-normalized-difference-vegetation-index#:~:text=NDVI%20is%20used%20to%20quantify), which is a widely-used measure of “greenness” and higher values of NDVI indicate a greater amount of green vegetation within each neighborhood. From USGS (text is quoted):\n",
    "\n",
    "NDVI is used to quantify vegetation greenness and is useful in understanding vegetation density and assessing changes in plant health. NDVI is calculated as a ratio between the red (R) and near infrared (NIR) values in traditional fashion: \n",
    "    \n",
    "    (NIR - R) / (NIR + R)\n",
    "    In Landsat 4-7, NDVI = (Band 4 – Band 3) / (Band 4 + Band 3).\n",
    "    In Landsat 8-9, NDVI = (Band 5 – Band 4) / (Band 5 + Band 4).\n",
    "    \n",
    "Basically, NDVI use the ratio of red and near-red colors to see how green something on the ground is. This is because less green objects tend to be darker in the visable R spectrul (e.g. absorb a lot of red light) and bright in the NIR (relfect/emit a lot of NIR). That's why plants look great to us!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create NDVI from Landsat 8 raw DN\n",
    "\n",
    "def ndvi(b4_fn, b5_fn, out_fn):\n",
    "    \"\"\"Funciton writes an NDVI image from Landsat 8. Will throw an error for 0 values in Landsat edges.\n",
    "    Args:\n",
    "        b4_fn = path to Landsat8 band 4 (red) geotif\n",
    "        b5_fn = path to Landsat8 band 5 (NIR) geotif\n",
    "        fn_out = path and name to write out ndvi file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get meta data to write file\n",
    "    meta = rasterio.open(b4_fn).meta\n",
    "    meta.update({'dtype': 'float32'})\n",
    "    \n",
    "    # Open the band data as arrays\n",
    "    band4 = rasterio.open(b4_fn).read(1) #Red\n",
    "    band5 = rasterio.open(b5_fn).read(1) #NIR\n",
    "    \n",
    "    # NDVI = (NIR — VIS)/(NIR + VIS) \n",
    "    ndvi = np.nan_to_num((band5 - band4)/(band5 + band4))\n",
    "    ndvi = np.float32(ndvi) # reduce size\n",
    "    \n",
    "    # write our raster to disk\n",
    "    with rasterio.open(out_fn, 'w', **meta) as out:\n",
    "        out.write_band(1, ndvi)\n",
    "\n",
    "    print('NDVI done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process 2020-04-14 NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up file paths\n",
    "data_in = os.path.join(file_path, 'landsat/Level1/LC08_L1TP_041036_20200414_20200423_01_T1')\n",
    "b4 = os.path.join(data_in, 'LC08_L1TP_041036_20200414_20200423_01_T1_B4.TIF')\n",
    "b5 = os.path.join(data_in, 'LC08_L1TP_041036_20200414_20200423_01_T1_B5.TIF')\n",
    "fn_out = os.path.join('./data/', 'NDVI_20200414.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "ndvi(b4, b5, fn_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process 2020-08-20 NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up file paths\n",
    "data_in = os.path.join(file_path, 'landsat/Level1/LC08_L1TP_041036_20200820_20200905_01_T1/')\n",
    "b4 = os.path.join(data_in, 'LC08_L1TP_041036_20200820_20200905_01_T1_B4.TIF')\n",
    "b5 = os.path.join(data_in, 'LC08_L1TP_041036_20200820_20200905_01_T1_B5.TIF')\n",
    "fn_out = os.path.join('./data/','NDVI_20200820.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "ndvi(b4, b5, fn_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On your own ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2020-04-14 NDVI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 2020-04-14 NDVI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2020-08-20 NDVI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 2020-08-20 NDVI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between 2020-08-20 and 2020-04-14 NDVI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the difference between 2020-08-20 and 2020-04-14 NDVI data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: \n",
    "Given that the 2020-04-14 image is spring (e.g. wet) and the 2020-08-20 image is summer (e.g. dry) in LA, does the difference between 2020-08-20 and 2020-04-14 NDVI data make sense? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "\n",
    "Now we need to estimate BT and NDVI for each neighborhood in LA. This requires using [rasters_stats](https://pythonhosted.org/rasterstats/) to calculate zonal statistics. In this case, we are going to do area-averaging of BT and NDVI. Doing so will add spatial uncertainty to our data because we are ascribing the same BT or NDVI value across an entire neigbhorhood (read about `all_touched` [here](https://pythonhosted.org/rasterstats/manual.html#zonal-statistics) as one example of possible error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5:\n",
    "\n",
    "What other issues of spatial uncertainty are introduced when overlaying vector data on raster data? Think about coastlines, reference systems, spatial resolution, etc. etc.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the area average\n",
    "\n",
    "def zonal(rst_in, polys_in, do_stats): \n",
    "    \"\"\"Function will run zonal stats on a raster and a set of polygons. All touched is set to True by default. \n",
    "    \n",
    "    Args:\n",
    "        rst_in = file name/path of raster to run zonal stats on\n",
    "        polys = either list of shape files (watersheds) or single shape file (countries)\n",
    "        do_stats = stats to use, see rasterstats package for documention, (use sume)\n",
    "    \"\"\"\n",
    "    \n",
    "    # project landsat to polygons crs\n",
    "    polys_in = polys_in.to_crs({'init' :'epsg:32611'}) # CRS of Landsat tifs\n",
    "    \n",
    "    # Run Zonal Stats\n",
    "    zs_feats = zonal_stats(polys_in, rst_in, stats= do_stats, geojson_out=True, all_touched=True)\n",
    "        \n",
    "    # Turn into geo data frame and rename column\n",
    "    zgdf = gpd.GeoDataFrame.from_features(zs_feats, crs=polys_in.crs)\n",
    "    \n",
    "    return zgdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Polygon Geometry \n",
    "polys_in =neighborhoods[['Name', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Zonal stats - Throws error for Catalina Island which isn't in the scene \n",
    "rst_in = os.path.join('./data/','NDVI_20200414.tif')\n",
    "ndvi_spring = zonal(rst_in, polys_in, 'mean')\n",
    "ndvi_spring.rename(columns = {'mean' : 'NDVI_SPRING'}, inplace = True)\n",
    "\n",
    "rst_in = os.path.join('./data/', 'NDVI_20200820.tif')\n",
    "ndvi_summer = zonal(rst_in, polys_in, 'mean')\n",
    "ndvi_summer.rename(columns = {'mean' : 'NDVI_SUMMER'}, inplace = True)\n",
    "\n",
    "rst_in = os.path.join('./data/', 'BT_20200414.tif')\n",
    "temp_spring = zonal(rst_in, polys_in, 'mean')\n",
    "temp_spring.rename(columns = {'mean' : 'TEMP_SPRING'}, inplace = True)\n",
    "\n",
    "rst_in = os.path.join('./data/', 'BT_20200820.tif')\n",
    "temp_summer = zonal(rst_in, polys_in, 'mean')\n",
    "temp_summer.rename(columns = {'mean' : 'TEMP_SUMMER'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out one of the dataframes\n",
    "temp_summer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the zonal stats data frames\n",
    "df_list = [ndvi_spring, ndvi_summer, temp_spring, temp_summer]\n",
    "\n",
    "# Loop and merge the data frames onto \n",
    "for df in df_list:\n",
    "    df.rename(columns = {'Name' : 'NEIGHBORHOOD'}, inplace = True)\n",
    "    df_out = df_out.merge(df.iloc[:,1:3], on = 'NEIGHBORHOOD', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out your final data\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write CSV\n",
    "fn_out = os.path.join('./data/','LA-all-SE-ENV-data')\n",
    "df_out.to_csv(fn_out+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write shape file\n",
    "gdf_out = neighborhoods[['Name','geometry']] # get name and geom\n",
    "gdf_out.rename(columns={'Name':'NEIGHBORHOOD'}, inplace=True) # rename col\n",
    "gdf_out = df_out.merge(gdf_out, on = 'NEIGHBORHOOD', how = 'right') # merge\n",
    "gdf_out = gpd.GeoDataFrame(gdf_out) # cast to GeoPandas DF\n",
    "gdf_out.to_file(fn_out+'.shp', index = False) # Write Shape file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6\n",
    "\n",
    "Finally, we have our dataset! Now, on your own, using `seaborn` and/or `matplotlib`, you will make a series of bi-variate plots where you look at the relationship between socioeconomic status, BT, and NDVI for LA. You will answer a series of questions as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On your own ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the relationship between spring NDVI and spring BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the relationship between summer NDVI and spring BT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: \n",
    "At the neighborhood-level, how well correlated are NDVI and BT? Is the relationship stronger in spring or summer?\n",
    "Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make 3-5 plots exploring the relationship between the various demographic and SE datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: \n",
    "Which demographic and SE data are most well correlated at the neighbhorhood level? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make 3-5 plots exploring the relationship between the various demographic and SE datasets and BT and NDVI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: \n",
    "Which demographic and SE data are most well correlated with BT and NDVI at the neighbhorhood level? Does BT or NDVI correlate better with demographic and SE data? Why? Which correlations, or lack of correlation, are most surprising?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
